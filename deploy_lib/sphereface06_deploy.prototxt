name: "SpherefaceNet-06"
input: "data"
input_dim: 1
input_dim: 3
input_dim: 112
input_dim: 96
############## CNN Architecture ###############
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 2
    pad: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {    
  name: "batchnorm1"    
  type: "BatchNorm"   
  bottom: "conv1_1"    
  top: "conv1_1"     
  param {    
    lr_mult: 0    
    decay_mult: 0    
  }     
  param {    
    lr_mult: 0    
    decay_mult: 0    
  }    
  param {    
    lr_mult: 0    
    decay_mult: 0    
  }  
}    
  
layer {    
  name: "scale1"    
  type: "Scale"  
  bottom: "conv1_1"    
  top: "conv1_1"      
  scale_param {    
    bias_term: true    
  }    
}  
layer {
  name: "relu1_1"
  type: "PReLU"
  bottom: "conv1_1"
  top: "conv1_1"
  prelu_param {
    filler {
      type: "gaussian"
      std: 0.03
    }
  }
}

layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 3
    stride: 2
    pad: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {    
  name: "batchnorm2"    
  type: "BatchNorm"   
  bottom: "conv2_1"    
  top: "conv2_1"     
  param {    
    lr_mult: 0    
    decay_mult: 0    
  }     
  param {    
    lr_mult: 0    
    decay_mult: 0    
  }    
  param {    
    lr_mult: 0    
    decay_mult: 0    
  }  
}    
  
layer {    
  name: "scale2"    
  type: "Scale"  
  bottom: "conv2_1"    
  top: "conv2_1"      
  scale_param {    
    bias_term: true    
  }    
}  
layer {
  name: "relu2_1"
  type: "PReLU"
  bottom: "conv2_1"
  top: "conv2_1"
  prelu_param {
    filler {
      type: "gaussian"
      std: 0.03
    }
  }
}

layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
    stride: 2
    pad: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {    
  name: "batchnorm3"    
  type: "BatchNorm"   
  bottom: "conv3_1"    
  top: "conv3_1"     
  param {    
    lr_mult: 0    
    decay_mult: 0    
  }     
  param {    
    lr_mult: 0    
    decay_mult: 0    
  }    
  param {    
    lr_mult: 0    
    decay_mult: 0    
  }  
}    
  
layer {    
  name: "scale3"    
  type: "Scale"  
  bottom: "conv3_1"    
  top: "conv3_1"      
  scale_param {    
    bias_term: true    
  }    
}  
layer {
  name: "relu3_1"
  type: "PReLU"
  bottom: "conv3_1"
  top: "conv3_1"
  prelu_param {
    filler {
      type: "gaussian"
      std: 0.03
    }
  }
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
    stride: 1
    pad: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {    
  name: "batchnorm3_2"    
  type: "BatchNorm"   
  bottom: "conv3_2"    
  top: "conv3_2"     
  param {    
    lr_mult: 0    
    decay_mult: 0    
  }     
  param {    
    lr_mult: 0    
    decay_mult: 0    
  }    
  param {    
    lr_mult: 0    
    decay_mult: 0    
  }  
}    
  
layer {    
  name: "scale3_2"    
  type: "Scale"  
  bottom: "conv3_2"    
  top: "conv3_2"      
  scale_param {    
    bias_term: true    
  }    
}  
layer {
  name: "relu3_2"
  type: "PReLU"
  bottom: "conv3_2"
  top: "conv3_2"
  prelu_param {
    filler {
      type: "gaussian"
      std: 0.03
    }
  }
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
    stride: 1
    pad: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {    
  name: "batchnorm3_3"    
  type: "BatchNorm"   
  bottom: "conv3_3"    
  top: "conv3_3"     
  param {    
    lr_mult: 0    
    decay_mult: 0    
  }     
  param {    
    lr_mult: 0    
    decay_mult: 0    
  }    
  param {    
    lr_mult: 0    
    decay_mult: 0    
  }  
}    
  
layer {    
  name: "scale3_3"    
  type: "Scale"  
  bottom: "conv3_3"    
  top: "conv3_3"      
  scale_param {    
    bias_term: true    
  }    
}  
layer {
  name: "relu3_3"
  type: "PReLU"
  bottom: "conv3_3"
  top: "conv3_3"
  prelu_param {
    filler {
      type: "gaussian"
      std: 0.03
    }
  }
}
layer {
  name: "res3_3"
  type: "Eltwise"
  bottom: "conv3_1"
  bottom: "conv3_3"
  top: "res3_3"
  eltwise_param { 
    operation: 1
  }
}

layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "res3_3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 2
    pad: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {    
  name: "batchnorm4"    
  type: "BatchNorm"   
  bottom: "conv4_1"    
  top: "conv4_1"     
  param {    
    lr_mult: 0    
    decay_mult: 0    
  }     
  param {    
    lr_mult: 0    
    decay_mult: 0    
  }    
  param {    
    lr_mult: 0    
    decay_mult: 0    
  }  
}    
  
layer {    
  name: "scale4"    
  type: "Scale"  
  bottom: "conv4_1"    
  top: "conv4_1"      
  scale_param {    
    bias_term: true    
  }    
}  
layer {
  name: "relu4_1"
  type: "PReLU"
  bottom: "conv4_1"
  top: "conv4_1"
  prelu_param {
    filler {
      type: "gaussian"
      std: 0.03
    }
  }
}

layer {
  name: "fc5"
  type: "InnerProduct"
  bottom: "conv4_1"
  top: "fc5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {    
  name: "batchnorm5"    
  type: "BatchNorm"   
  bottom: "fc5"    
  top: "fc5"     
  param {    
    lr_mult: 0    
    decay_mult: 0    
  }     
  param {    
    lr_mult: 0    
    decay_mult: 0    
  }    
  param {    
    lr_mult: 0    
    decay_mult: 0    
  }  
}    
  
layer {    
  name: "scale5"    
  type: "Scale"  
  bottom: "fc5"    
  top: "fc5"      
  scale_param {    
    bias_term: true    
  }    
} 
layer {
  name: "l2"
  type: "L2Norm"
  bottom: "fc5"
  top: "l2"
}
layer {
  name: "silence"
  type: "Silence"
  bottom: "l2"
}

